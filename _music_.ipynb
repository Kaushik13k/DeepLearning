{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23bfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "# !pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac6c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to read MIDI files\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc37d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: schubert/schubert_D850_1.mid\n",
      "Loading Music File: schubert/schubert_D850_2.mid\n",
      "Loading Music File: schubert/schubert_D850_3.mid\n",
      "Loading Music File: schubert/schubert_D850_4.mid\n",
      "Loading Music File: schubert/schubert_D935_1.mid\n",
      "Loading Music File: schubert/schubert_D935_2.mid\n",
      "Loading Music File: schubert/schubert_D935_3.mid\n",
      "Loading Music File: schubert/schubert_D935_4.mid\n",
      "Loading Music File: schubert/schub_d760_1.mid\n",
      "Loading Music File: schubert/schub_d760_2.mid\n",
      "Loading Music File: schubert/schub_d760_3.mid\n",
      "Loading Music File: schubert/schub_d760_4.mid\n",
      "Loading Music File: schubert/schub_d960_1.mid\n",
      "Loading Music File: schubert/schub_d960_2.mid\n",
      "Loading Music File: schubert/schub_d960_3.mid\n",
      "Loading Music File: schubert/schub_d960_4.mid\n",
      "Loading Music File: schubert/schuim-1.mid\n",
      "Loading Music File: schubert/schuim-2.mid\n",
      "Loading Music File: schubert/schuim-3.mid\n",
      "Loading Music File: schubert/schuim-4.mid\n",
      "Loading Music File: schubert/schumm-1.mid\n",
      "Loading Music File: schubert/schumm-2.mid\n",
      "Loading Music File: schubert/schumm-3.mid\n",
      "Loading Music File: schubert/schumm-4.mid\n",
      "Loading Music File: schubert/schumm-5.mid\n",
      "Loading Music File: schubert/schumm-6.mid\n",
      "Loading Music File: schubert/schu_143_1.mid\n",
      "Loading Music File: schubert/schu_143_2.mid\n",
      "Loading Music File: schubert/schu_143_3.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-13269b8794bc>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  notes_array = np.array([read_midi(path+i) for i in files])\n"
     ]
    }
   ],
   "source": [
    "#for listing down the file names\n",
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#specify the path\n",
    "path='schubert/'\n",
    "\n",
    "#read all the filenames\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d04354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dcaf3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([186.,  46.,  27.,  10.,   4.,   6.,   6.,  12.,   8.,   3.]),\n",
       " array([1.0000e+00, 1.7290e+02, 3.4480e+02, 5.1670e+02, 6.8860e+02,\n",
       "        8.6050e+02, 1.0324e+03, 1.2043e+03, 1.3762e+03, 1.5481e+03,\n",
       "        1.7200e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 324
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef4a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f807004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-2fa7923ce1b3>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  new_music = np.array(new_music)\n"
     ]
    }
   ],
   "source": [
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9986bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "befa59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1457f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "625520f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c1a1dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d4cb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128,return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac743b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 100)           17300     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 173)               44461     \n",
      "=================================================================\n",
      "Total params: 270,081\n",
      "Trainable params: 270,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c11c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15a99ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "503/503 [==============================] - 74s 70ms/step - loss: 4.5726 - val_loss: 3.9890\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.98900, saving model to best_model.h5\n",
      "Epoch 2/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 3.8047 - val_loss: 3.8049\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.98900 to 3.80489, saving model to best_model.h5\n",
      "Epoch 3/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 3.5957 - val_loss: 3.6585\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.80489 to 3.65849, saving model to best_model.h5\n",
      "Epoch 4/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 3.4564 - val_loss: 3.5448\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.65849 to 3.54477, saving model to best_model.h5\n",
      "Epoch 5/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 3.3675 - val_loss: 3.4656\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.54477 to 3.46559, saving model to best_model.h5\n",
      "Epoch 6/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 3.2866 - val_loss: 3.4091\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.46559 to 3.40910, saving model to best_model.h5\n",
      "Epoch 7/50\n",
      "503/503 [==============================] - 33s 66ms/step - loss: 3.2048 - val_loss: 3.3396\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.40910 to 3.33957, saving model to best_model.h5\n",
      "Epoch 8/50\n",
      "503/503 [==============================] - 34s 68ms/step - loss: 3.1525 - val_loss: 3.2996\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.33957 to 3.29957, saving model to best_model.h5\n",
      "Epoch 9/50\n",
      "503/503 [==============================] - 34s 67ms/step - loss: 3.0872 - val_loss: 3.2832\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.29957 to 3.28321, saving model to best_model.h5\n",
      "Epoch 10/50\n",
      "503/503 [==============================] - 34s 67ms/step - loss: 3.0349 - val_loss: 3.2329\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.28321 to 3.23289, saving model to best_model.h5\n",
      "Epoch 11/50\n",
      "503/503 [==============================] - 34s 67ms/step - loss: 2.9903 - val_loss: 3.2072\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.23289 to 3.20718, saving model to best_model.h5\n",
      "Epoch 12/50\n",
      "503/503 [==============================] - 19s 37ms/step - loss: 2.9519 - val_loss: 3.1879\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.20718 to 3.18788, saving model to best_model.h5\n",
      "Epoch 13/50\n",
      "503/503 [==============================] - 21s 43ms/step - loss: 2.9093 - val_loss: 3.1794\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.18788 to 3.17944, saving model to best_model.h5\n",
      "Epoch 14/50\n",
      "503/503 [==============================] - 21s 43ms/step - loss: 2.8819 - val_loss: 3.1171\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.17944 to 3.11707, saving model to best_model.h5\n",
      "Epoch 15/50\n",
      "503/503 [==============================] - 21s 43ms/step - loss: 2.8515 - val_loss: 3.1060\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.11707 to 3.10600, saving model to best_model.h5\n",
      "Epoch 16/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.8165 - val_loss: 3.1098\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.10600\n",
      "Epoch 17/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.8009 - val_loss: 3.0735\n",
      "\n",
      "Epoch 00017: val_loss improved from 3.10600 to 3.07354, saving model to best_model.h5\n",
      "Epoch 18/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.7791 - val_loss: 3.0464\n",
      "\n",
      "Epoch 00018: val_loss improved from 3.07354 to 3.04639, saving model to best_model.h5\n",
      "Epoch 19/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.7419 - val_loss: 3.0530\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.04639\n",
      "Epoch 20/50\n",
      "503/503 [==============================] - 23s 45ms/step - loss: 2.7315 - val_loss: 3.0331\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.04639 to 3.03306, saving model to best_model.h5\n",
      "Epoch 21/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.7055 - val_loss: 3.0327\n",
      "\n",
      "Epoch 00021: val_loss improved from 3.03306 to 3.03269, saving model to best_model.h5\n",
      "Epoch 22/50\n",
      "503/503 [==============================] - 21s 43ms/step - loss: 2.6804 - val_loss: 3.0204\n",
      "\n",
      "Epoch 00022: val_loss improved from 3.03269 to 3.02035, saving model to best_model.h5\n",
      "Epoch 23/50\n",
      "503/503 [==============================] - 21s 43ms/step - loss: 2.6718 - val_loss: 2.9878\n",
      "\n",
      "Epoch 00023: val_loss improved from 3.02035 to 2.98785, saving model to best_model.h5\n",
      "Epoch 24/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.6544 - val_loss: 2.9859\n",
      "\n",
      "Epoch 00024: val_loss improved from 2.98785 to 2.98586, saving model to best_model.h5\n",
      "Epoch 25/50\n",
      "503/503 [==============================] - 21s 43ms/step - loss: 2.6403 - val_loss: 2.9718\n",
      "\n",
      "Epoch 00025: val_loss improved from 2.98586 to 2.97179, saving model to best_model.h5\n",
      "Epoch 26/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.6162 - val_loss: 2.9636\n",
      "\n",
      "Epoch 00026: val_loss improved from 2.97179 to 2.96359, saving model to best_model.h5\n",
      "Epoch 27/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.6036 - val_loss: 2.9611\n",
      "\n",
      "Epoch 00027: val_loss improved from 2.96359 to 2.96108, saving model to best_model.h5\n",
      "Epoch 28/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.5964 - val_loss: 2.9461\n",
      "\n",
      "Epoch 00028: val_loss improved from 2.96108 to 2.94614, saving model to best_model.h5\n",
      "Epoch 29/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.5796 - val_loss: 2.9400\n",
      "\n",
      "Epoch 00029: val_loss improved from 2.94614 to 2.94003, saving model to best_model.h5\n",
      "Epoch 30/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.5634 - val_loss: 2.9297\n",
      "\n",
      "Epoch 00030: val_loss improved from 2.94003 to 2.92966, saving model to best_model.h5\n",
      "Epoch 31/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.5562 - val_loss: 2.9381\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.92966\n",
      "Epoch 32/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.5493 - val_loss: 2.9288\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.92966 to 2.92884, saving model to best_model.h5\n",
      "Epoch 33/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.5381 - val_loss: 2.9122\n",
      "\n",
      "Epoch 00033: val_loss improved from 2.92884 to 2.91219, saving model to best_model.h5\n",
      "Epoch 34/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.5251 - val_loss: 2.9024\n",
      "\n",
      "Epoch 00034: val_loss improved from 2.91219 to 2.90237, saving model to best_model.h5\n",
      "Epoch 35/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.5160 - val_loss: 2.8941\n",
      "\n",
      "Epoch 00035: val_loss improved from 2.90237 to 2.89410, saving model to best_model.h5\n",
      "Epoch 36/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.5091 - val_loss: 2.8845\n",
      "\n",
      "Epoch 00036: val_loss improved from 2.89410 to 2.88453, saving model to best_model.h5\n",
      "Epoch 37/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.5059 - val_loss: 2.8885\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.88453\n",
      "Epoch 38/50\n",
      "503/503 [==============================] - 22s 44ms/step - loss: 2.4952 - val_loss: 2.8858\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.88453\n",
      "Epoch 39/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.4851 - val_loss: 2.8861\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.88453\n",
      "Epoch 40/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.4846 - val_loss: 2.8746\n",
      "\n",
      "Epoch 00040: val_loss improved from 2.88453 to 2.87456, saving model to best_model.h5\n",
      "Epoch 41/50\n",
      "503/503 [==============================] - 22s 44ms/step - loss: 2.4756 - val_loss: 2.8682\n",
      "\n",
      "Epoch 00041: val_loss improved from 2.87456 to 2.86818, saving model to best_model.h5\n",
      "Epoch 42/50\n",
      "503/503 [==============================] - 22s 44ms/step - loss: 2.4806 - val_loss: 2.8630\n",
      "\n",
      "Epoch 00042: val_loss improved from 2.86818 to 2.86301, saving model to best_model.h5\n",
      "Epoch 43/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.4647 - val_loss: 2.8709\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.86301\n",
      "Epoch 44/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.4533 - val_loss: 2.8643\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.86301\n",
      "Epoch 45/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.4493 - val_loss: 2.8470\n",
      "\n",
      "Epoch 00045: val_loss improved from 2.86301 to 2.84704, saving model to best_model.h5\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503/503 [==============================] - 21s 43ms/step - loss: 2.4467 - val_loss: 2.8449\n",
      "\n",
      "Epoch 00046: val_loss improved from 2.84704 to 2.84488, saving model to best_model.h5\n",
      "Epoch 47/50\n",
      "503/503 [==============================] - 21s 43ms/step - loss: 2.4316 - val_loss: 2.8555\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.84488\n",
      "Epoch 48/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.4476 - val_loss: 2.8297\n",
      "\n",
      "Epoch 00048: val_loss improved from 2.84488 to 2.82970, saving model to best_model.h5\n",
      "Epoch 49/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.4249 - val_loss: 2.8266\n",
      "\n",
      "Epoch 00049: val_loss improved from 2.82970 to 2.82664, saving model to best_model.h5\n",
      "Epoch 50/50\n",
      "503/503 [==============================] - 22s 43ms/step - loss: 2.4304 - val_loss: 2.8276\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.82664\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9669c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92cf5629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 16, 62, 134, 119, 134, 62, 134, 167, 42]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "predictions=[]\n",
    "for i in range(10):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "472df2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6de0b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ede278ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = convert_to_midi(predicted_notes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
